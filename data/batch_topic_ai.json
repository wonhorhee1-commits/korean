{
  "주제별 단어 — 인공지능 (Topic: AI & Machine Learning)": [
    {
      "korean": "신경망",
      "english": "neural network",
      "example": "딥러닝은 여러 층의 신경망으로 구성되어 복잡한 패턴을 학습할 수 있다.",
      "example_en": "Deep learning can learn complex patterns through neural networks composed of multiple layers."
    },
    {
      "korean": "딥러닝",
      "english": "deep learning",
      "example": "요즘 이미지 인식 기술은 대부분 딥러닝 기반으로 구현되어 있다.",
      "example_en": "Most image recognition technology nowadays is based on deep learning."
    },
    {
      "korean": "자연어 처리",
      "english": "natural language processing (NLP)",
      "example": "자연어 처리 기술이 발전하면서 기계 번역의 정확도가 크게 향상되었다.",
      "example_en": "As NLP technology advances, machine translation accuracy has greatly improved."
    },
    {
      "korean": "컴퓨터 시각",
      "english": "computer vision",
      "example": "컴퓨터 시각 분야에서 트랜스포머 모델을 적용한 연구가 최근 주목을 받고 있다.",
      "example_en": "Recent research applying transformer models in computer vision is receiving attention."
    },
    {
      "korean": "강화학습",
      "english": "reinforcement learning",
      "example": "강화학습은 보상과 페널티를 통해 에이전트가 최적의 행동을 학습하는 방식이다.",
      "example_en": "Reinforcement learning is a method where agents learn optimal behavior through rewards and penalties."
    },
    {
      "korean": "훈련 데이터",
      "english": "training data",
      "example": "모델의 성능은 훈련 데이터의 품질과 양에 크게 영향을 받는다.",
      "example_en": "Model performance is heavily influenced by the quality and quantity of training data."
    },
    {
      "korean": "과적합",
      "english": "overfitting",
      "example": "과적합을 방지하기 위해 규제 기법과 조기 종료를 사용한다.",
      "example_en": "Regularization techniques and early stopping are used to prevent overfitting."
    },
    {
      "korean": "편향",
      "english": "bias",
      "example": "학습 데이터의 편향은 모델이 특정 그룹에 불공정한 예측을 하도록 할 수 있다.",
      "example_en": "Bias in training data can cause models to make unfair predictions for certain groups."
    },
    {
      "korean": "트랜스포머",
      "english": "transformer",
      "example": "트랜스포머는 주의 메커니즘을 기반으로 하며 병렬 처리가 가능해 매우 효율적이다.",
      "example_en": "Transformers are based on attention mechanisms and enable efficient parallel processing."
    },
    {
      "korean": "생성형 AI",
      "english": "generative AI",
      "example": "생성형 AI는 텍스트, 이미지, 음성 등 새로운 콘텐츠를 만들 수 있다.",
      "example_en": "Generative AI can create new content such as text, images, and speech."
    },
    {
      "korean": "언어 모델",
      "english": "language model",
      "example": "대규모 언어 모델은 방대한 텍스트 데이터에서 언어의 패턴을 학습한다.",
      "example_en": "Large language models learn language patterns from vast amounts of text data."
    },
    {
      "korean": "자율주행",
      "english": "autonomous driving",
      "example": "자율주행 기술은 컴퓨터 시각, 센서 융합, 의사결정 알고리즘 등 여러 분야를 통합한다.",
      "example_en": "Autonomous driving technology integrates computer vision, sensor fusion, and decision-making algorithms."
    },
    {
      "korean": "추천 시스템",
      "english": "recommendation system",
      "example": "추천 시스템은 사용자의 과거 행동을 분석하여 관심 있을 만한 항목을 제안한다.",
      "example_en": "Recommendation systems analyze user behavior to suggest items they might be interested in."
    },
    {
      "korean": "챗봇",
      "english": "chatbot",
      "example": "최신 챗봇들은 문맥을 이해하고 자연스러운 대화를 나눌 수 있다.",
      "example_en": "Modern chatbots can understand context and engage in natural conversations."
    },
    {
      "korean": "프롬프트 엔지니어링",
      "english": "prompt engineering",
      "example": "프롬프트 엔지니어링은 AI 모델으로부터 원하는 결과를 얻기 위해 질문을 세심하게 설계하는 기술이다.",
      "example_en": "Prompt engineering is the technique of carefully designing questions to get desired results from AI models."
    },
    {
      "korean": "환각",
      "english": "hallucination",
      "example": "언어 모델이 환각을 일으키면 그럴듯하지만 사실이 아닌 정보를 생성할 수 있다.",
      "example_en": "When language models hallucinate, they can generate plausible but factually incorrect information."
    },
    {
      "korean": "알고리즘",
      "english": "algorithm",
      "example": "머신러닝 알고리즘은 데이터에서 패턴을 찾아 예측 모델을 구축한다.",
      "example_en": "Machine learning algorithms find patterns in data to build predictive models."
    },
    {
      "korean": "머신러닝",
      "english": "machine learning",
      "example": "머신러닝은 명시적으로 프로그래밍하지 않아도 데이터로부터 학습하는 기술이다.",
      "example_en": "Machine learning is technology that learns from data without being explicitly programmed."
    },
    {
      "korean": "검증 데이터",
      "english": "validation data",
      "example": "검증 데이터를 사용하여 모델의 하이퍼파라미터를 조정하고 과적합을 감지한다.",
      "example_en": "Validation data is used to tune hyperparameters and detect overfitting."
    },
    {
      "korean": "테스트 데이터",
      "english": "test data",
      "example": "모델의 최종 성능은 학습에 사용되지 않은 테스트 데이터로 평가해야 한다.",
      "example_en": "Final model performance should be evaluated on test data that was not used for training."
    },
    {
      "korean": "하이퍼파라미터",
      "english": "hyperparameter",
      "example": "학습률, 배치 크기, 신경망 깊이는 모두 중요한 하이퍼파라미터이다.",
      "example_en": "Learning rate, batch size, and neural network depth are all important hyperparameters."
    },
    {
      "korean": "정규화",
      "english": "regularization",
      "example": "정규화는 복잡한 모델에 페널티를 주어 과적합을 줄이는 기법이다.",
      "example_en": "Regularization is a technique that penalizes complex models to reduce overfitting."
    },
    {
      "korean": "활성화 함수",
      "english": "activation function",
      "example": "ReLU는 현대 신경망에서 가장 널리 사용되는 활성화 함수이다.",
      "example_en": "ReLU is the most widely used activation function in modern neural networks."
    },
    {
      "korean": "손실 함수",
      "english": "loss function",
      "example": "분류 문제에서는 교차 엔트로피가 일반적인 손실 함수로 사용된다.",
      "example_en": "Cross-entropy is commonly used as the loss function for classification problems."
    },
    {
      "korean": "기울기 하강법",
      "english": "gradient descent",
      "example": "기울기 하강법은 모델의 가중치를 반복적으로 업데이트하여 손실을 최소화한다.",
      "example_en": "Gradient descent iteratively updates model weights to minimize loss."
    },
    {
      "korean": "역전파",
      "english": "backpropagation",
      "example": "역전파는 신경망에서 오류를 역방향으로 전파하여 가중치를 조정한다.",
      "example_en": "Backpropagation propagates error backward through the network to adjust weights."
    },
    {
      "korean": "합성곱 신경망",
      "english": "convolutional neural network (CNN)",
      "example": "합성곱 신경망은 이미지 인식 작업에서 탁월한 성능을 보인다.",
      "example_en": "Convolutional neural networks excel at image recognition tasks."
    },
    {
      "korean": "순환 신경망",
      "english": "recurrent neural network (RNN)",
      "example": "순환 신경망은 시계열 데이터나 자연어 처리에 적합하다.",
      "example_en": "Recurrent neural networks are suitable for time series data and natural language processing."
    },
    {
      "korean": "장단기 메모리",
      "english": "long short-term memory (LSTM)",
      "example": "LSTM은 장기 의존성을 학습할 수 있어 기계 번역에 자주 사용된다.",
      "example_en": "LSTM can learn long-term dependencies and is frequently used in machine translation."
    },
    {
      "korean": "주의 메커니즘",
      "english": "attention mechanism",
      "example": "주의 메커니즘을 통해 모델은 입력 시퀀스의 중요한 부분에 집중할 수 있다.",
      "example_en": "Through attention mechanisms, models can focus on important parts of the input sequence."
    },
    {
      "korean": "임베딩",
      "english": "embedding",
      "example": "단어 임베딩은 의미론적으로 유사한 단어들을 벡터 공간에서 가깝게 배치한다.",
      "example_en": "Word embeddings place semantically similar words close together in vector space."
    },
    {
      "korean": "토큰화",
      "english": "tokenization",
      "example": "자연어 처리에서 토큰화는 텍스트를 작은 단위로 분할하는 첫 단계이다.",
      "example_en": "Tokenization is the first step in NLP, splitting text into smaller units."
    },
    {
      "korean": "인코더",
      "english": "encoder",
      "example": "인코더는 입력 데이터를 의미 있는 표현으로 압축한다.",
      "example_en": "An encoder compresses input data into a meaningful representation."
    },
    {
      "korean": "디코더",
      "english": "decoder",
      "example": "디코더는 인코더에서 생성된 표현으로부터 최종 출력을 생성한다.",
      "example_en": "A decoder generates the final output from the representation created by the encoder."
    },
    {
      "korean": "파인튜닝",
      "english": "fine-tuning",
      "example": "사전 학습된 모델에 파인튜닝을 적용하면 적은 데이터로도 좋은 성능을 얻을 수 있다.",
      "example_en": "Fine-tuning pre-trained models can achieve good performance even with limited data."
    },
    {
      "korean": "전이 학습",
      "english": "transfer learning",
      "example": "전이 학습은 한 작업에서 학습한 지식을 다른 작업에 적용하는 기법이다.",
      "example_en": "Transfer learning applies knowledge learned in one task to another task."
    },
    {
      "korean": "분류",
      "english": "classification",
      "example": "이메일이 스팸인지 아닌지 판단하는 것은 대표적인 분류 문제이다.",
      "example_en": "Determining whether an email is spam is a typical classification problem."
    },
    {
      "korean": "회귀",
      "english": "regression",
      "example": "주택 가격을 예측하는 것은 회귀 문제의 예이다.",
      "example_en": "Predicting house prices is an example of a regression problem."
    },
    {
      "korean": "클러스터링",
      "english": "clustering",
      "example": "클러스터링은 유사한 데이터 포인트를 그룹으로 묶는 비지도 학습 방식이다.",
      "example_en": "Clustering is an unsupervised learning method that groups similar data points together."
    },
    {
      "korean": "이상 탐지",
      "english": "anomaly detection",
      "example": "이상 탐지 기술은 사기 거래나 시스템 오류를 자동으로 감지할 수 있다.",
      "example_en": "Anomaly detection can automatically identify fraudulent transactions or system errors."
    }
  ]
}
